{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "#import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sympy.stats.sampling.sample_numpy import numpy\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "#from core.model import MultiOutputRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "#from core.visualize import export_and_visualize_model\n",
    "import joblib"
   ],
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5cdf1e4cc8d926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (1170, 254)\n",
      "Columns in dataset: ['ChEMBL ID', 'Smiles', 'FC', 'N', 'H', 'Cl', 'Br', 'I', 'P', 'F', 'Se', 'Si', 'S_sp3', 'S_sp2', 'S_sp', 'C_sp3', 'C_sp2', 'C_sp', 'N_sp3', 'N_sp2', 'N_sp', 'O_sp3', 'O_sp2', 'O_sp', 'I1', 'I2', 'I3', 'sp3sp3', 'sp3sp2', 'sp3sp', 'sp3s', 'sp2sp2', 'sp2sp', 'sp2s', 'spsp', 'sps', 'other', 'MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'HallKierAlpha', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAmideBonds', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumAtomStereoCenters', 'NumBridgeheadAtoms', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumHeterocycles', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'NumSpiroAtoms', 'NumUnspecifiedAtomStereoCenters', 'Phi', 'RingCount', 'MolLogP', 'MolMR', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea', 'IC50 (nM)']\n",
      "Number of feature columns: 253\n",
      "Found 65 IC50 values with duplicates\n",
      "\n",
      "Processing IC50 =  0.590 with 2 rows\n",
      "\n",
      "Processing IC50 =  0.710 with 2 rows\n",
      "\n",
      "Processing IC50 =  8.00 with 4 rows\n",
      "\n",
      "Processing IC50 =  9.00 with 2 rows\n",
      "\n",
      "Processing IC50 = <10.00 with 127 rows\n",
      "Rows 37 and 38 are too similar (4 differing features). Marking 38 for removal.\n",
      "Rows 40 and 41 are too similar (5 differing features). Marking 41 for removal.\n",
      "Rows 551 and 553 are too similar (5 differing features). Marking 553 for removal.\n",
      "Rows 552 and 562 are too similar (5 differing features). Marking 562 for removal.\n",
      "Rows 555 and 556 are too similar (4 differing features). Marking 556 for removal.\n",
      "Rows 564 and 565 are too similar (5 differing features). Marking 565 for removal.\n",
      "Rows 566 and 568 are too similar (5 differing features). Marking 568 for removal.\n",
      "Rows 579 and 580 are too similar (5 differing features). Marking 580 for removal.\n",
      "Rows 581 and 583 are too similar (5 differing features). Marking 583 for removal.\n",
      "Rows 825 and 829 are too similar (4 differing features). Marking 829 for removal.\n",
      "Rows 841 and 842 are too similar (5 differing features). Marking 842 for removal.\n",
      "Rows 843 and 865 are too similar (4 differing features). Marking 865 for removal.\n",
      "Rows 851 and 866 are too similar (4 differing features). Marking 866 for removal.\n",
      "Rows 857 and 864 are too similar (4 differing features). Marking 864 for removal.\n",
      "\n",
      "Processing IC50 =  10.00 with 5 rows\n",
      "\n",
      "Processing IC50 =  55.0 with 280 rows\n",
      "Rows 65 and 66 are too similar (4 differing features). Marking 66 for removal.\n",
      "Rows 67 and 68 are too similar (4 differing features). Marking 68 for removal.\n",
      "Rows 71 and 72 are too similar (4 differing features). Marking 72 for removal.\n",
      "Rows 77 and 78 are too similar (4 differing features). Marking 78 for removal.\n",
      "Rows 77 and 80 are too similar (5 differing features). Marking 80 for removal.\n",
      "Rows 78 and 80 are too similar (5 differing features). Marking 80 for removal.\n",
      "Rows 83 and 104 are too similar (4 differing features). Marking 104 for removal.\n",
      "Rows 88 and 105 are too similar (4 differing features). Marking 105 for removal.\n",
      "Rows 102 and 103 are too similar (4 differing features). Marking 103 for removal.\n",
      "Rows 117 and 1106 are too similar (5 differing features). Marking 1106 for removal.\n",
      "Rows 120 and 995 are too similar (6 differing features). Marking 995 for removal.\n",
      "Rows 123 and 974 are too similar (5 differing features). Marking 974 for removal.\n",
      "Rows 124 and 976 are too similar (5 differing features). Marking 976 for removal.\n",
      "Rows 125 and 967 are too similar (5 differing features). Marking 967 for removal.\n",
      "Rows 970 and 971 are too similar (5 differing features). Marking 971 for removal.\n",
      "Rows 979 and 980 are too similar (5 differing features). Marking 980 for removal.\n",
      "Rows 987 and 988 are too similar (5 differing features). Marking 988 for removal.\n",
      "Rows 997 and 998 are too similar (4 differing features). Marking 998 for removal.\n",
      "Rows 1005 and 1006 are too similar (4 differing features). Marking 1006 for removal.\n",
      "Rows 1005 and 1007 are too similar (4 differing features). Marking 1007 for removal.\n",
      "Rows 1006 and 1007 are too similar (4 differing features). Marking 1007 for removal.\n",
      "Rows 1010 and 1011 are too similar (4 differing features). Marking 1011 for removal.\n",
      "Rows 1010 and 1012 are too similar (4 differing features). Marking 1012 for removal.\n",
      "Rows 1011 and 1012 are too similar (4 differing features). Marking 1012 for removal.\n",
      "Rows 1017 and 1018 are too similar (4 differing features). Marking 1018 for removal.\n",
      "Rows 1024 and 1025 are too similar (4 differing features). Marking 1025 for removal.\n",
      "Rows 1032 and 1033 are too similar (6 differing features). Marking 1033 for removal.\n",
      "Rows 1032 and 1034 are too similar (6 differing features). Marking 1034 for removal.\n",
      "Rows 1033 and 1034 are too similar (5 differing features). Marking 1034 for removal.\n",
      "Rows 1035 and 1046 are too similar (5 differing features). Marking 1046 for removal.\n",
      "Rows 1039 and 1040 are too similar (5 differing features). Marking 1040 for removal.\n",
      "Rows 1039 and 1049 are too similar (6 differing features). Marking 1049 for removal.\n",
      "Rows 1040 and 1049 are too similar (6 differing features). Marking 1049 for removal.\n",
      "Rows 1041 and 1042 are too similar (5 differing features). Marking 1042 for removal.\n",
      "Rows 1057 and 1058 are too similar (4 differing features). Marking 1058 for removal.\n",
      "Rows 1078 and 1079 are too similar (5 differing features). Marking 1079 for removal.\n",
      "Rows 1100 and 1104 are too similar (5 differing features). Marking 1104 for removal.\n",
      "Rows 1113 and 1114 are too similar (5 differing features). Marking 1114 for removal.\n",
      "Rows 1118 and 1121 are too similar (5 differing features). Marking 1121 for removal.\n",
      "Rows 1120 and 1150 are too similar (4 differing features). Marking 1150 for removal.\n",
      "Rows 1123 and 1124 are too similar (4 differing features). Marking 1124 for removal.\n",
      "Rows 1142 and 1143 are too similar (4 differing features). Marking 1143 for removal.\n",
      "Rows 1155 and 1156 are too similar (4 differing features). Marking 1156 for removal.\n",
      "Rows 1161 and 1162 are too similar (4 differing features). Marking 1162 for removal.\n",
      "Rows 1163 and 1164 are too similar (4 differing features). Marking 1164 for removal.\n",
      "Rows 1166 and 1167 are too similar (4 differing features). Marking 1167 for removal.\n",
      "\n",
      "Processing IC50 =  59.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  60.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  64.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  71.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  73.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  84.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  162 with 2 rows\n",
      "\n",
      "Processing IC50 =  200 with 3 rows\n",
      "\n",
      "Processing IC50 =  240 with 4 rows\n",
      "\n",
      "Processing IC50 =  251 with 2 rows\n",
      "\n",
      "Processing IC50 =  290 with 2 rows\n",
      "\n",
      "Processing IC50 =  350 with 2 rows\n",
      "\n",
      "Processing IC50 =  360 with 2 rows\n",
      "\n",
      "Processing IC50 =  465 with 2 rows\n",
      "\n",
      "Processing IC50 =  550 with 276 rows\n",
      "Rows 207 and 478 are too similar (5 differing features). Marking 478 for removal.\n",
      "Rows 214 and 225 are too similar (5 differing features). Marking 225 for removal.\n",
      "Rows 217 and 224 are too similar (5 differing features). Marking 224 for removal.\n",
      "Rows 222 and 473 are too similar (5 differing features). Marking 473 for removal.\n",
      "Rows 231 and 250 are too similar (5 differing features). Marking 250 for removal.\n",
      "Rows 235 and 241 are too similar (6 differing features). Marking 241 for removal.\n",
      "Rows 238 and 239 are too similar (5 differing features). Marking 239 for removal.\n",
      "Rows 243 and 244 are too similar (6 differing features). Marking 244 for removal.\n",
      "Rows 246 and 411 are too similar (5 differing features). Marking 411 for removal.\n",
      "Rows 254 and 482 are too similar (6 differing features). Marking 482 for removal.\n",
      "Rows 266 and 267 are too similar (5 differing features). Marking 267 for removal.\n",
      "Rows 269 and 277 are too similar (5 differing features). Marking 277 for removal.\n",
      "Rows 282 and 284 are too similar (5 differing features). Marking 284 for removal.\n",
      "Rows 293 and 294 are too similar (5 differing features). Marking 294 for removal.\n",
      "Rows 302 and 303 are too similar (6 differing features). Marking 303 for removal.\n",
      "Rows 310 and 311 are too similar (5 differing features). Marking 311 for removal.\n",
      "Rows 313 and 314 are too similar (5 differing features). Marking 314 for removal.\n",
      "Rows 333 and 334 are too similar (6 differing features). Marking 334 for removal.\n",
      "Rows 365 and 436 are too similar (5 differing features). Marking 436 for removal.\n",
      "Rows 365 and 437 are too similar (5 differing features). Marking 437 for removal.\n",
      "Rows 370 and 371 are too similar (4 differing features). Marking 371 for removal.\n",
      "Rows 384 and 385 are too similar (4 differing features). Marking 385 for removal.\n",
      "Rows 387 and 388 are too similar (4 differing features). Marking 388 for removal.\n",
      "Rows 392 and 393 are too similar (4 differing features). Marking 393 for removal.\n",
      "Rows 394 and 401 are too similar (5 differing features). Marking 401 for removal.\n",
      "Rows 397 and 398 are too similar (4 differing features). Marking 398 for removal.\n",
      "Rows 399 and 400 are too similar (4 differing features). Marking 400 for removal.\n",
      "Rows 399 and 428 are too similar (5 differing features). Marking 428 for removal.\n",
      "Rows 400 and 428 are too similar (5 differing features). Marking 428 for removal.\n",
      "Rows 407 and 408 are too similar (4 differing features). Marking 408 for removal.\n",
      "Rows 415 and 416 are too similar (4 differing features). Marking 416 for removal.\n",
      "Rows 417 and 418 are too similar (4 differing features). Marking 418 for removal.\n",
      "Rows 422 and 423 are too similar (4 differing features). Marking 423 for removal.\n",
      "Rows 424 and 425 are too similar (4 differing features). Marking 425 for removal.\n",
      "Rows 432 and 433 are too similar (4 differing features). Marking 433 for removal.\n",
      "Rows 434 and 435 are too similar (4 differing features). Marking 435 for removal.\n",
      "Rows 436 and 437 are too similar (4 differing features). Marking 437 for removal.\n",
      "Rows 438 and 439 are too similar (4 differing features). Marking 439 for removal.\n",
      "Rows 440 and 441 are too similar (4 differing features). Marking 441 for removal.\n",
      "Rows 450 and 451 are too similar (4 differing features). Marking 451 for removal.\n",
      "Rows 452 and 469 are too similar (4 differing features). Marking 469 for removal.\n",
      "Rows 453 and 467 are too similar (4 differing features). Marking 467 for removal.\n",
      "Rows 454 and 455 are too similar (4 differing features). Marking 455 for removal.\n",
      "\n",
      "Processing IC50 =  806 with 2 rows\n",
      "Rows 495 and 496 are too similar (4 differing features). Marking 496 for removal.\n",
      "\n",
      "Processing IC50 =  880 with 2 rows\n",
      "\n",
      "Processing IC50 =  1200 with 5 rows\n",
      "\n",
      "Processing IC50 =  1300 with 2 rows\n",
      "\n",
      "Processing IC50 =  1400 with 3 rows\n",
      "Rows 520 and 521 are too similar (4 differing features). Marking 521 for removal.\n",
      "\n",
      "Processing IC50 =  1900 with 2 rows\n",
      "\n",
      "Processing IC50 =  2100 with 2 rows\n",
      "\n",
      "Processing IC50 =  2300 with 4 rows\n",
      "Rows 533 and 535 are too similar (4 differing features). Marking 535 for removal.\n",
      "Rows 534 and 536 are too similar (4 differing features). Marking 536 for removal.\n",
      "\n",
      "Processing IC50 =  2600 with 2 rows\n",
      "\n",
      "Processing IC50 =  2900 with 3 rows\n",
      "\n",
      "Processing IC50 =  3500 with 2 rows\n",
      "Rows 597 and 598 are too similar (4 differing features). Marking 598 for removal.\n",
      "\n",
      "Processing IC50 =  4000 with 3 rows\n",
      "\n",
      "Processing IC50 = >5000 with 7 rows\n",
      "\n",
      "Processing IC50 =  5300 with 2 rows\n",
      "Rows 615 and 616 are too similar (4 differing features). Marking 616 for removal.\n",
      "\n",
      "Processing IC50 =  5500 with 102 rows\n",
      "Rows 635 and 636 are too similar (4 differing features). Marking 636 for removal.\n",
      "Rows 638 and 639 are too similar (4 differing features). Marking 639 for removal.\n",
      "Rows 640 and 641 are too similar (4 differing features). Marking 641 for removal.\n",
      "Rows 644 and 645 are too similar (4 differing features). Marking 645 for removal.\n",
      "Rows 646 and 647 are too similar (4 differing features). Marking 647 for removal.\n",
      "Rows 648 and 649 are too similar (4 differing features). Marking 649 for removal.\n",
      "Rows 650 and 651 are too similar (4 differing features). Marking 651 for removal.\n",
      "Rows 660 and 661 are too similar (4 differing features). Marking 661 for removal.\n",
      "Rows 663 and 664 are too similar (4 differing features). Marking 664 for removal.\n",
      "Rows 668 and 669 are too similar (4 differing features). Marking 669 for removal.\n",
      "Rows 670 and 671 are too similar (4 differing features). Marking 671 for removal.\n",
      "Rows 672 and 673 are too similar (4 differing features). Marking 673 for removal.\n",
      "Rows 676 and 677 are too similar (4 differing features). Marking 677 for removal.\n",
      "Rows 676 and 678 are too similar (4 differing features). Marking 678 for removal.\n",
      "Rows 677 and 678 are too similar (4 differing features). Marking 678 for removal.\n",
      "Rows 679 and 680 are too similar (4 differing features). Marking 680 for removal.\n",
      "Rows 679 and 681 are too similar (4 differing features). Marking 681 for removal.\n",
      "Rows 680 and 681 are too similar (4 differing features). Marking 681 for removal.\n",
      "Rows 682 and 683 are too similar (4 differing features). Marking 683 for removal.\n",
      "Rows 684 and 685 are too similar (4 differing features). Marking 685 for removal.\n",
      "Rows 686 and 687 are too similar (4 differing features). Marking 687 for removal.\n",
      "Rows 688 and 689 are too similar (4 differing features). Marking 689 for removal.\n",
      "Rows 690 and 691 are too similar (4 differing features). Marking 691 for removal.\n",
      "Rows 692 and 693 are too similar (4 differing features). Marking 693 for removal.\n",
      "Rows 694 and 695 are too similar (4 differing features). Marking 695 for removal.\n",
      "Rows 696 and 697 are too similar (4 differing features). Marking 697 for removal.\n",
      "Rows 698 and 699 are too similar (4 differing features). Marking 699 for removal.\n",
      "Rows 708 and 709 are too similar (4 differing features). Marking 709 for removal.\n",
      "Rows 710 and 711 are too similar (4 differing features). Marking 711 for removal.\n",
      "Rows 718 and 719 are too similar (4 differing features). Marking 719 for removal.\n",
      "\n",
      "Processing IC50 = >10000 with 28 rows\n",
      "Rows 739 and 740 are too similar (5 differing features). Marking 740 for removal.\n",
      "\n",
      "Processing IC50 =  13500 with 2 rows\n",
      "Rows 756 and 757 are too similar (4 differing features). Marking 757 for removal.\n",
      "\n",
      "Processing IC50 =  13900 with 2 rows\n",
      "\n",
      "Processing IC50 =  15000 with 4 rows\n",
      "\n",
      "Processing IC50 =  23400 with 2 rows\n",
      "\n",
      "Processing IC50 =  25300 with 2 rows\n",
      "Rows 775 and 776 are too similar (4 differing features). Marking 776 for removal.\n",
      "\n",
      "Processing IC50 =  25500 with 2 rows\n",
      "Rows 777 and 778 are too similar (4 differing features). Marking 778 for removal.\n",
      "\n",
      "Processing IC50 =  43000 with 2 rows\n",
      "Rows 781 and 782 are too similar (4 differing features). Marking 782 for removal.\n",
      "\n",
      "Processing IC50 = >50000 with 34 rows\n",
      "Rows 793 and 796 are too similar (4 differing features). Marking 796 for removal.\n",
      "Rows 794 and 797 are too similar (4 differing features). Marking 797 for removal.\n",
      "Rows 795 and 798 are too similar (4 differing features). Marking 798 for removal.\n",
      "\n",
      "Processing IC50 =  11.0 with 7 rows\n",
      "\n",
      "Processing IC50 =  12.0 with 7 rows\n",
      "\n",
      "Processing IC50 =  13.0 with 6 rows\n",
      "\n",
      "Processing IC50 =  14.0 with 4 rows\n",
      "\n",
      "Processing IC50 =  15.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  17.0 with 3 rows\n",
      "\n",
      "Processing IC50 =  18.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  19.0 with 3 rows\n",
      "\n",
      "Processing IC50 =  20.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  23.0 with 3 rows\n",
      "\n",
      "Processing IC50 =  25.0 with 3 rows\n",
      "\n",
      "Processing IC50 =  26.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  27.0 with 3 rows\n",
      "\n",
      "Processing IC50 =  32.0 with 5 rows\n",
      "\n",
      "Processing IC50 =  33.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  35.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  38.0 with 2 rows\n",
      "\n",
      "Processing IC50 =  43.0 with 3 rows\n",
      "\n",
      "Processing IC50 =  53.0 with 2 rows\n",
      "\n",
      "Total rows marked for removal: 138\n",
      "Filtered dataset shape: (1032, 254)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import argparse\n",
    "from itertools import combinations\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"/Users/user/PycharmProjects/Drug Design FInal/FINAL_GIT/Raw Files/merged_features_IC50_g12c.csv\")\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "\n",
    "# Print available columns\n",
    "print(\"Columns in dataset:\", df.columns.tolist())\n",
    "\n",
    "# Identify feature columns (exclude IC50)\n",
    "feature_cols = [col for col in df.columns if col != 'IC50 (nM)']\n",
    "print(f\"Number of feature columns: {len(feature_cols)}\")\n",
    "\n",
    "# Create a mask to keep rows\n",
    "rows_to_keep = pd.Series([True] * len(df), index=df.index)\n",
    "\n",
    "# Identify duplicated IC50 values\n",
    "duplicated_ic50_values = df['IC50 (nM)'][df['IC50 (nM)'].duplicated(keep=False)].unique()\n",
    "print(f\"Found {len(duplicated_ic50_values)} IC50 values with duplicates\")\n",
    "\n",
    "total_removed = 0\n",
    "\n",
    "for ic50 in duplicated_ic50_values:\n",
    "    group = df[df['IC50 (nM)'] == ic50]\n",
    "    indices_to_remove = set()\n",
    "\n",
    "    print(f\"\\nProcessing IC50 = {ic50} with {len(group)} rows\")\n",
    "\n",
    "    # Compare all pairs of rows within the group\n",
    "    for idx1, idx2 in combinations(group.index, 2):\n",
    "        row1 = group.loc[idx1, feature_cols]\n",
    "        row2 = group.loc[idx2, feature_cols]\n",
    "\n",
    "        # Count how many features differ (NaNs handled as unequal)\n",
    "        num_differences = (row1 != row2).sum()\n",
    "\n",
    "        if num_differences < 25:\n",
    "            print(f\"Rows {idx1} and {idx2} are too similar ({num_differences} differing features). Marking {idx2} for removal.\")\n",
    "            indices_to_remove.add(idx2)\n",
    "\n",
    "    # Update global mask\n",
    "    rows_to_keep.loc[list(indices_to_remove)] = False\n",
    "    total_removed += len(indices_to_remove)\n",
    "\n",
    "print(f\"\\nTotal rows marked for removal: {total_removed}\")\n",
    "filtered_df = df[rows_to_keep].reset_index(drop=True)\n",
    "print(f\"Filtered dataset shape: {filtered_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b27319ad114f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5adb408a24a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    DF = pd.read_csv(\"merged_features_IC50_g12d.csv\", index_col=False)\n",
    "    DF = DF.dropna()\n",
    "    DF = DF.loc[:, ~DF.columns.str.contains('^Unnamed')]\n",
    "    DF['IC50 (nM)'] = pd.to_numeric(DF['IC50 (nM)'], errors='coerce')\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "    Q1 = DF['IC50 (nM)'].quantile(0.25)\n",
    "    Q3 = DF['IC50 (nM)'].quantile(0.75)\n",
    "\n",
    "    # Calculate IQR\n",
    "    IQR = Q3 - Q1\n",
    "    # Relax the conditions by increasing the multiplier\n",
    "    multiplier = 0.6  # You can change this to a value that suits your needs\n",
    "\n",
    "    # Remove outliers using the relaxed IQR method\n",
    "    DF = DF[(DF['IC50 (nM)'] >= (Q1 - multiplier * IQR)) & (DF['IC50 (nM)'] <= (Q3 + multiplier * IQR))]\n",
    "    DF = DF.reset_index(drop=True)\n",
    "\n",
    "    # Filter and sample data\n",
    "    DF = DF[DF['FC'] == 0]\n",
    "\n",
    "    DF = DF.sample(frac=10, replace=True, random_state=42)  # Shuffle data\n",
    "\n",
    "    y = DF[[\"IC50 (nM)\"]] #  \"IC50 (nM)\"\n",
    "    X = DF.drop(columns=[\"FC\", \"IC50 (nM)\", \"Smiles\", \"ChEMBL ID\"])\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Scale the data\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_y = StandardScaler()\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "    y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "\n",
    "    #joblib.dump(scaler_X, f\"saved_models/scaler_X_{chembel_id}_SV.pkl\")\n",
    "    #joblib.dump(scaler_y, f\"saved_models/scaler_y_{chembel_id}_SV.pkl\")\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.from_numpy(X_train_scaled).float()\n",
    "    X_test_tensor = torch.from_numpy(X_test_scaled).float()\n",
    "    y_train_tensor = torch.from_numpy(y_train_scaled).float()\n",
    "    y_test_tensor = torch.from_numpy(y_test_scaled).float()\n",
    "\n",
    "\n",
    "    # Model, loss, optimizer, and scheduler\n",
    "    input_dim = X_train_tensor.shape[1]\n",
    "    hidden_dim = 104  # Increased hidden dimension\n",
    "    num_hidden_layers = 4\n",
    "    output_dim = y_train_tensor.shape[1]\n",
    "    dropout_rate = 0.0\n",
    "\n",
    "\n",
    "    class MultiOutputNN(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim, num_hidden_layers, dropout_rate):\n",
    "            super(MultiOutputNN, self).__init__()\n",
    "            layers = []\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            for _ in range(num_hidden_layers - 1):\n",
    "                layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "            self.model = nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "\n",
    "    # Now create the model\n",
    "    model = MultiOutputNN(input_dim, hidden_dim, output_dim, num_hidden_layers, dropout_rate)\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()  # Huber loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0041, weight_decay=1e-6)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "    # Prepare DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    train_losses, test_losses, r2_scores = [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        train_losses.append(epoch_train_loss / len(train_loader))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        epoch_test_loss = 0\n",
    "        y_pred_test_all, y_test_all = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                y_pred = model(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                epoch_test_loss += loss.item()\n",
    "                y_pred_test_all.append(y_pred)\n",
    "                y_test_all.append(y_batch)\n",
    "        test_losses.append(epoch_test_loss / len(test_loader))\n",
    "\n",
    "        # Calculate R2 score\n",
    "        y_pred_test_all = torch.cat(y_pred_test_all, dim=0).cpu().numpy()\n",
    "        y_test_all = torch.cat(y_test_all, dim=0).cpu().numpy()\n",
    "        r2 = r2_score(y_test_all, y_pred_test_all, multioutput='variance_weighted')\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}, R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10f7c9d9307fe3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:49:53.909234Z",
     "start_time": "2025-02-28T14:49:53.901151Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate final R2\n",
    "final_r2 = r2_scores[-1]\n",
    "MAE = mean_squared_error(y_test_all, y_pred_test_all)\n",
    "print(f\"Final R2 Score: {final_r2:.4f}\")\n",
    "print(f\"MSE: {MAE:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc501bbff5fa2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
