{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-03T13:46:29.718678Z",
     "start_time": "2025-04-03T13:46:28.559557Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:46:29.843640Z",
     "start_time": "2025-04-03T13:46:29.730191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df2 = pd.read_csv(\"/Users/user/PycharmProjects/Drug Design FInal/FINAL_GIT/Raw Files/merged_features_IC50_g12d.csv\")\n",
    "df2"
   ],
   "id": "56227294735f6752",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:46:30.061812Z",
     "start_time": "2025-04-03T13:46:30.052302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def pIC50(input):\n",
    "    pIC50 = []\n",
    "\n",
    "    input[\"IC50 (nM)\"] = pd.to_numeric(input[\"IC50 (nM)\"],errors='coerce')\n",
    "\n",
    "    for i in input[\"IC50 (nM)\"]:\n",
    "        molar = i*(10**-9) # Converts nM to M\n",
    "        pIC50.append(-np.log10(molar))\n",
    "\n",
    "    input['pIC50'] = pIC50\n",
    "    x = input[\"pIC50\"]\n",
    "\n",
    "    return x"
   ],
   "id": "5ccfcd2128863469",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:46:42.247269Z",
     "start_time": "2025-04-03T13:46:42.152683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename = \"/Users/user/PycharmProjects/Drug Design FInal/FINAL_GIT/Raw Files/merged_features_IC50_g12d.csv\"\n",
    "#df = pd.read_csv(\"fda_original.csv\",sep=\";\")\n",
    "df2 = pd.read_csv(filename)\n",
    "df2.dropna(subset=['IC50 (nM)'], inplace=True)\n",
    "df2['IC50 (nM)'] = pIC50(df2)\n",
    "df2['IC50 (nM)'] = df2['pIC50']  # Replace 'SV' column with pIC50 values\n",
    "\n",
    "# Drop 'pIC50' column (optional) as it's now redundant\n",
    "df2.drop(columns=['pIC50'], inplace=True)\n",
    "\n",
    "df2"
   ],
   "id": "c9e106c2f55cd6dc",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:51:40.030741Z",
     "start_time": "2025-04-03T13:47:20.122952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load training descriptors data\n",
    "#df1 = df1.loc[:, ~df1.columns.str.contains('Unnamed')]\n",
    "df2.dropna(subset=['IC50 (nM)'], inplace=True)\n",
    "X = df2.drop(columns=['IC50 (nM)','Smiles', 'ChEMBL ID'])\n",
    "y = df2['IC50 (nM)']\n",
    "\n",
    "# Initialize model and pipeline\n",
    "model = RandomForestRegressor(max_depth=20, min_samples_leaf=10)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('model', model)])\n",
    "\n",
    "# Load new descriptors data\n",
    "new_descriptors = pd.read_csv('C:\\\\Users\\Gebruiker\\Desktop\\pycharm\\FDA_Hyb_Features.csv')\n",
    "new_descriptors.dropna(inplace=True)\n",
    "\n",
    "# Extract ChEMBL IDs and SMILES\n",
    "chembl_id_column = new_descriptors['ChEMBL ID']\n",
    "smiles_column = new_descriptors['Smiles']\n",
    "new_descriptors.drop(columns=['ChEMBL ID', 'Smiles'], inplace=True)\n",
    "\n",
    "# Ensure new_descriptors has the same columns as X\n",
    "missing_cols = set(X.columns) - set(new_descriptors.columns)  # Columns missing in new data\n",
    "extra_cols = set(new_descriptors.columns) - set(X.columns)  # Extra columns in new data\n",
    "\n",
    "# Add missing columns with zero values\n",
    "for col in missing_cols:\n",
    "    new_descriptors[col] = 0\n",
    "\n",
    "# Drop extra columns\n",
    "new_descriptors = new_descriptors[X.columns]  # Reorder and drop extras\n",
    "\n",
    "# Now X and new_descriptors have identical columns\n",
    "\n",
    "# Initialize a DataFrame to store results\n",
    "loop_results_df = pd.DataFrame(columns=['ChEMBL ID', 'Smiles', 'Predicted Value'])\n",
    "\n",
    "# Number of iterations\n",
    "loop_n = 50\n",
    "\n",
    "# Dictionary to store predicted values for each ChEMBL ID\n",
    "predicted_values = {chembl_id: [] for chembl_id in chembl_id_column.unique()}\n",
    "feature_importances = []\n",
    "perm_importances = []\n",
    "# Run the loop to fit the model and predict the values\n",
    "for i in range(loop_n):\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    # Get regular feature importance\n",
    "    rf_model = pipe.named_steps['model']\n",
    "    feature_importances.append(rf_model.feature_importances_)\n",
    "\n",
    "    # Get permutation importance\n",
    "    result = permutation_importance(pipe, X, y, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "    perm_importances.append(result.importances_mean)\n",
    "\n",
    "    loop_predicted_values = pipe.predict(new_descriptors)\n",
    "\n",
    "    loop_df = pd.DataFrame({\n",
    "        'ChEMBL ID': chembl_id_column,\n",
    "        'Smiles': smiles_column,\n",
    "        'Predicted Value': loop_predicted_values\n",
    "    })\n",
    "    loop_df.sort_values(by='Predicted Value', ascending=False, inplace=True)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "        loop_results_df = pd.concat([loop_results_df, loop_df.head(10)])\n",
    "\n",
    "    # Store the predicted values for each ChEMBL ID\n",
    "    for chembl_id, predicted_value in zip(chembl_id_column, loop_predicted_values):\n",
    "        if chembl_id in predicted_values:\n",
    "            predicted_values[chembl_id].append(predicted_value)\n",
    "\n",
    "# Average the importances across all iterations\n",
    "avg_feature_importance = np.mean(feature_importances, axis=0)\n",
    "avg_perm_importance = np.mean(perm_importances, axis=0)\n",
    "\n",
    "# Create DataFrames for visualization\n",
    "feature_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': avg_feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': avg_perm_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot Mean Decrease Impurity feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_df.head(10).sort_values('Importance', ascending=True).plot.barh(\n",
    "    x='Feature', y='Importance', color='skyblue'\n",
    ")\n",
    "plt.title('Top 10 Features - Mean Decrease Impurity')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('MDI_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot Permutation Importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "perm_df.head(10).sort_values('Importance', ascending=True).plot.barh(\n",
    "    x='Feature', y='Importance', color='lightgreen'\n",
    ")\n",
    "plt.title('Top 10 Features - Permutation Importance')\n",
    "plt.xlabel('Mean Accuracy Decrease')\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('permutation_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate frequency of each ChEMBL ID in the top 10\n",
    "value_counts = loop_results_df['ChEMBL ID'].value_counts(normalize=True) * 10\n",
    "#print(value_counts)\n",
    "\n",
    "# Get the top 13 ChEMBL IDs\n",
    "top_10_chembl_ids = value_counts.head(10).index"
   ],
   "id": "bd17efacb6e7cfeb",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:51:40.118048Z",
     "start_time": "2025-04-03T13:51:40.097625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_values = {chembl_id: np.mean(predicted_values[chembl_id]) for chembl_id in top_10_chembl_ids}\n",
    "std_dev_values = {chembl_id: np.std(predicted_values[chembl_id]) for chembl_id in top_10_chembl_ids}\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'ChEMBL ID': top_10_chembl_ids,\n",
    "    'Frequency': [value_counts[chembl_id] for chembl_id in top_10_chembl_ids],\n",
    "    'Avg Predicted Value': [mean_values[chembl_id] for chembl_id in top_10_chembl_ids]\n",
    "})\n",
    "\n",
    "summary_df.head(10)\n",
    "summary_df.to_csv(\"RF_molecules_Newfeatures_G12C.csv\", index=False)"
   ],
   "id": "8e7447e2cb36bbbb",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "id": "138ba714af485b88",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
