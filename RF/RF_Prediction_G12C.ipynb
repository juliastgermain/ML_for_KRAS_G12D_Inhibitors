{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "filename = \"../Raw_Files/G12C_training.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "df = df.drop_duplicates(subset=['Smiles', 'IC50 (nM)'])\n",
    "\n",
    "\n",
    "df = df.dropna()\n",
    "print(len(df))\n",
    "\n",
    "def pIC50(input_df):\n",
    "    input_df = input_df.copy()\n",
    "    input_df[\"IC50 (nM)\"] = pd.to_numeric(input_df[\"IC50 (nM)\"], errors='coerce')\n",
    "\n",
    "    # Replace zeros with a small value (1e-12 nM = 1e-21 M)\n",
    "    molar = np.where(input_df[\"IC50 (nM)\"] == 0,\n",
    "                     1e-12 * 1e-9,\n",
    "                     input_df[\"IC50 (nM)\"] * 1e-9)\n",
    "\n",
    "    return -np.log10(molar)\n",
    "# Filter and sample data before splitting\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "\n",
    "df = df.dropna(subset=['IC50 (nM)'])  # Remove rows with invalid IC50\n",
    "print(len(df))\n",
    "\n",
    "\n",
    "\n",
    "df = df[(df['FC'] == 0)] #& (df['IC50 (nM)'] <= 10)]\n",
    "y = df['IC50 (nM)']\n",
    "\n",
    "\n",
    "df['pIC50'] = pIC50(df)  # New column\n",
    "df = df[df['pIC50'] <= 20]\n",
    "print(len(df))\n",
    "\n",
    "y = df['pIC50']  # <-- Now using correct column\n",
    "X = df.drop(columns=[\"ChEMBL ID\", \"FC\", 'IC50 (nM)', \"Smiles\", \"pIC50\"])  # Drop old IC50 and new pIC50\n",
    "\n",
    "\n",
    "# --- Initialize Pipeline ---\n",
    "pipe = Pipeline([\n",
    "    ('variance_threshold', VarianceThreshold(threshold=0.8*(1-0.8))),\n",
    "    ('univariate_select', SelectKBest(score_func=f_regression, k=50)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(max_depth=20, min_samples_leaf=10, random_state=42))\n",
    "])\n",
    "\n",
    "# --- Load New Data ---\n",
    "new_descriptors = pd.read_csv('../Raw_Files/FDA_Hyb_Features.csv')\n",
    "new_descriptors.dropna(inplace=True)\n",
    "chembl_id_column = new_descriptors['ChEMBL ID']\n",
    "smiles_column = new_descriptors['Smiles']\n",
    "X_new = new_descriptors.drop(columns=['ChEMBL ID', 'Smiles'])\n",
    "\n",
    "# --- Align New Data with Training Features ---\n",
    "missing_cols = set(X.columns) - set(X_new.columns)\n",
    "for col in missing_cols:\n",
    "    X_new[col] = 0  # Add missing columns with 0\n",
    "X_new = X_new[X.columns]  # Ensure column order matches\n",
    "\n",
    "# --- Track Results ---\n",
    "loop_results_df = pd.DataFrame(columns=['ChEMBL ID', 'Smiles', 'Predicted Value'])\n",
    "predicted_values = {chembl_id: [] for chembl_id in chembl_id_column.unique()}\n",
    "feature_importances = []\n",
    "perm_importances = []\n",
    "all_selected_features = []\n",
    "\n",
    "# --- Main Loop ---\n",
    "for i in range(50):  # 50 iterations\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    # Get selected features for this iteration\n",
    "    vt_mask = pipe.named_steps['variance_threshold'].get_support()\n",
    "    remaining_features = X.columns[vt_mask].tolist()\n",
    "    skb_mask = pipe.named_steps['univariate_select'].get_support()\n",
    "    selected_features = [remaining_features[i] for i in range(len(remaining_features)) if skb_mask[i]]\n",
    "    all_selected_features.append(selected_features)\n",
    "    \n",
    "    # Predict\n",
    "    loop_predicted_values = pipe.predict(X_new)\n",
    "    \n",
    "    # Store predictions\n",
    "    loop_df = pd.DataFrame({\n",
    "        'ChEMBL ID': chembl_id_column,\n",
    "        'Smiles': smiles_column,\n",
    "        'Predicted Value': loop_predicted_values\n",
    "    }).sort_values('Predicted Value', ascending=False)\n",
    "    \n",
    "    loop_results_df = pd.concat([loop_results_df, loop_df.head(10)])\n",
    "    \n",
    "    # Store predicted values per ChEMBL ID\n",
    "    for chembl_id, pred in zip(chembl_id_column, loop_predicted_values):\n",
    "        predicted_values[chembl_id].append(pred)\n",
    "    \n",
    "    # Get feature importances (only for selected features)\n",
    "    rf_model = pipe.named_steps['model']\n",
    "    feature_importances.append(rf_model.feature_importances_)\n",
    "    \n",
    "    # Get permutation importance (on selected features)\n",
    "    X_transformed = pipe[:-1].transform(X)  # Apply all steps except model\n",
    "    result = permutation_importance(\n",
    "        pipe.named_steps['model'], \n",
    "        X_transformed, \n",
    "        y, \n",
    "        n_repeats=10, \n",
    "        random_state=42\n",
    "    )\n",
    "    perm_importances.append(result.importances_mean)\n",
    "\n",
    "# --- Post-Processing ---\n",
    "# Average importances (only for selected features)\n",
    "avg_feature_importance = np.mean(feature_importances, axis=0)\n",
    "avg_perm_importance = np.mean(perm_importances, axis=0)\n",
    "\n",
    "# Create importance DataFrames\n",
    "feature_df = pd.DataFrame({\n",
    "    'Feature': selected_features,  # Use the last iteration's selected features\n",
    "    'Importance': avg_feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': avg_perm_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# --- Analyze Top Predictions ---\n",
    "value_counts = loop_results_df['ChEMBL ID'].value_counts(normalize=True) * 10\n",
    "top_10_chembl_ids = value_counts.head(10).index"
   ],
   "id": "8298688ca443e9d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot Permutation Importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "perm_df.head(10).sort_values('Importance', ascending=True).plot.barh(\n",
    "    x='Feature', y='Importance', color='skyblue'\n",
    ")\n",
    "plt.title('Top 10 Features - Permutation Importance')\n",
    "plt.xlabel('Mean Accuracy Decrease')\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "970fabf7c7df74b4"
  },
  {
   "cell_type": "code",
   "id": "8e7447e2cb36bbbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:01:08.980615Z",
     "start_time": "2025-05-10T10:01:08.953971Z"
    }
   },
   "source": [
    "mean_values = {chembl_id: np.mean(predicted_values[chembl_id]) for chembl_id in top_10_chembl_ids}\n",
    "std_dev_values = {chembl_id: np.std(predicted_values[chembl_id]) for chembl_id in top_10_chembl_ids}\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'ChEMBL ID': top_10_chembl_ids,\n",
    "    'Frequency': [value_counts[chembl_id] for chembl_id in top_10_chembl_ids],\n",
    "    'Avg Predicted Value': [mean_values[chembl_id] for chembl_id in top_10_chembl_ids]\n",
    "})\n",
    "\n",
    "summary_df.head(10)\n",
    "summary_df.to_csv(\"RF_Molecules_G12C.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
