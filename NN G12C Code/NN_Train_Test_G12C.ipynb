{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:48:29.585761Z",
     "start_time": "2025-02-28T14:48:29.580695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sympy.stats.sampling.sample_numpy import numpy\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "#from core.model import MultiOutputRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "#from core.visualize import export_and_visualize_model\n",
    "import joblib"
   ],
   "id": "37aa26bcf2e8e78b",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:49:09.520063Z",
     "start_time": "2025-02-28T14:48:29.847012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    DF = pd.read_csv(\"new_merged_features_IC50_g12c.csv\", index_col=False)\n",
    "    DF = DF.dropna()\n",
    "    DF = DF.loc[:, ~DF.columns.str.contains('^Unnamed')]\n",
    "    DF['IC50 (nM)'] = pd.to_numeric(DF['IC50 (nM)'], errors='coerce')\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "    Q1 = DF['IC50 (nM)'].quantile(0.25)\n",
    "    Q3 = DF['IC50 (nM)'].quantile(0.75)\n",
    "\n",
    "    # Calculate IQR\n",
    "    IQR = Q3 - Q1\n",
    "    # Relax the conditions by increasing the multiplier\n",
    "    multiplier = 0.6  # You can change this to a value that suits your needs\n",
    "\n",
    "    # Remove outliers using the relaxed IQR method\n",
    "    DF = DF[(DF['IC50 (nM)'] >= (Q1 - multiplier * IQR)) & (DF['IC50 (nM)'] <= (Q3 + multiplier * IQR))]\n",
    "    DF = DF.reset_index(drop=True)\n",
    "\n",
    "    # Filter and sample data\n",
    "    DF = DF[DF['FC'] == 0]\n",
    "\n",
    "    DF = DF.sample(frac=10, replace=True, random_state=42)  # Shuffle data\n",
    "\n",
    "    y = DF[[\"IC50 (nM)\"]] #  \"IC50 (nM)\"\n",
    "    X = DF.drop(columns=[\"FC\", \"IC50 (nM)\", \"Smiles\", \"ChEMBL ID\"])\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Scale the data\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_y = StandardScaler()\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "    y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "\n",
    "    #joblib.dump(scaler_X, f\"saved_models/scaler_X_{chembel_id}_SV.pkl\")\n",
    "    #joblib.dump(scaler_y, f\"saved_models/scaler_y_{chembel_id}_SV.pkl\")\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.from_numpy(X_train_scaled).float()\n",
    "    X_test_tensor = torch.from_numpy(X_test_scaled).float()\n",
    "    y_train_tensor = torch.from_numpy(y_train_scaled).float()\n",
    "    y_test_tensor = torch.from_numpy(y_test_scaled).float()\n",
    "\n",
    "\n",
    "    # Model, loss, optimizer, and scheduler\n",
    "    input_dim = X_train_tensor.shape[1]\n",
    "    hidden_dim = 104  # Increased hidden dimension\n",
    "    num_hidden_layers = 4\n",
    "    output_dim = y_train_tensor.shape[1]\n",
    "    dropout_rate = 0.0\n",
    "\n",
    "\n",
    "    class MultiOutputNN(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim, num_hidden_layers, dropout_rate):\n",
    "            super(MultiOutputNN, self).__init__()\n",
    "            layers = []\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            for _ in range(num_hidden_layers - 1):\n",
    "                layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "            self.model = nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "\n",
    "    # Now create the model\n",
    "    model = MultiOutputNN(input_dim, hidden_dim, output_dim, num_hidden_layers, dropout_rate)\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()  # Huber loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0041, weight_decay=1e-6)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "    # Prepare DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    train_losses, test_losses, r2_scores = [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        train_losses.append(epoch_train_loss / len(train_loader))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        epoch_test_loss = 0\n",
    "        y_pred_test_all, y_test_all = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                y_pred = model(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                epoch_test_loss += loss.item()\n",
    "                y_pred_test_all.append(y_pred)\n",
    "                y_test_all.append(y_batch)\n",
    "        test_losses.append(epoch_test_loss / len(test_loader))\n",
    "\n",
    "        # Calculate R2 score\n",
    "        y_pred_test_all = torch.cat(y_pred_test_all, dim=0).cpu().numpy()\n",
    "        y_test_all = torch.cat(y_test_all, dim=0).cpu().numpy()\n",
    "        r2 = r2_score(y_test_all, y_pred_test_all, multioutput='variance_weighted')\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}, R2: {r2:.4f}\")"
   ],
   "id": "4706e617fbf0a126",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:49:09.547898Z",
     "start_time": "2025-02-28T14:49:09.539555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate final R2\n",
    "final_r2 = r2_scores[-1]\n",
    "MAE = mean_squared_error(y_test_all, y_pred_test_all)\n",
    "print(f\"Final R2 Score: {final_r2:.4f}\")\n",
    "print(f\"MSE: {MAE:.4f}\")"
   ],
   "id": "bca220d0d8d80e4",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "23373a38f40c4fd2",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
